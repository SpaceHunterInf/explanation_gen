{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel, RobertaConfig, RobertaForSequenceClassification, pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import json, os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.1005, -1.4663,  5.8797]], grad_fn=<AddmmBackward0>)\n",
      "Premise: Two women are embracing while holding to go packages.\n",
      "Hypothesis: The men are fighting outside a deli.\n",
      "Entailment: 4.627431553672068e-05\n",
      "Neutral: 0.0006447185878641903\n",
      "Contradiction: 0.9993090629577637\n"
     ]
    }
   ],
   "source": [
    "max_length = 256\n",
    "\n",
    "premise = \"Two women are embracing while holding to go packages.\"\n",
    "hypothesis = \"The men are fighting outside a deli.\"\n",
    "\n",
    "# hg_model_hub_name = \"ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli\"\n",
    "hg_model_hub_name = \"ynie/albert-xxlarge-v2-snli_mnli_fever_anli_R1_R2_R3-nli\"\n",
    "# hg_model_hub_name = \"ynie/bart-large-snli_mnli_fever_anli_R1_R2_R3-nli\"\n",
    "# hg_model_hub_name = \"ynie/electra-large-discriminator-snli_mnli_fever_anli_R1_R2_R3-nli\"\n",
    "# hg_model_hub_name = \"ynie/xlnet-large-cased-snli_mnli_fever_anli_R1_R2_R3-nli\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(hg_model_hub_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(hg_model_hub_name)\n",
    "\n",
    "tokenized_input_seq_pair = tokenizer.encode_plus(premise, hypothesis,\n",
    "                                                    max_length=max_length,\n",
    "                                                    return_token_type_ids=True, truncation=True)\n",
    "\n",
    "input_ids = torch.Tensor(tokenized_input_seq_pair['input_ids']).long().unsqueeze(0)\n",
    "# remember bart doesn't have 'token_type_ids', remove the line below if you are using bart.\n",
    "token_type_ids = torch.Tensor(tokenized_input_seq_pair['token_type_ids']).long().unsqueeze(0)\n",
    "attention_mask = torch.Tensor(tokenized_input_seq_pair['attention_mask']).long().unsqueeze(0)\n",
    "\n",
    "outputs = model(input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids,\n",
    "                labels=None)\n",
    "# Note:\n",
    "# \"id2label\": {\n",
    "#     \"0\": \"entailment\",\n",
    "#     \"1\": \"neutral\",\n",
    "#     \"2\": \"contradiction\"\n",
    "# },\n",
    "print(outputs[0])\n",
    "predicted_probability = torch.softmax(outputs[0], dim=1)[0].tolist()  # batch_size only one\n",
    "\n",
    "print(\"Premise:\", premise)\n",
    "print(\"Hypothesis:\", hypothesis)\n",
    "print(\"Entailment:\", predicted_probability[0])\n",
    "print(\"Neutral:\", predicted_probability[1])\n",
    "print(\"Contradiction:\", predicted_probability[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = []\n",
    "\n",
    "with open('flan-t5/processed.json', 'r') as f:\n",
    "    flant5 = json.load(f)\n",
    "\n",
    "with open('flan-t5-prompted/processed.json', 'r') as f:\n",
    "    flant5prompted = json.load(f)\n",
    "\n",
    "with open('bloom/processed.json', 'r') as f:\n",
    "    bloom = json.load(f)\n",
    "\n",
    "with open('gpt-3.5/processed.json', 'r') as f:\n",
    "    gpt = json.load(f)\n",
    "\n",
    "processed_data += flant5 + flant5prompted + bloom + gpt\n",
    "random.shuffle(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': 'A young boy with black hair is holding onto a gun which is secured to a vehicle which is being driven by a young man who is wearing a bright pink shirt.',\n",
       " 'hypothesis': 'The boy is outside and running from cops.',\n",
       " 'uid': '4762813376.jpg#0r1n',\n",
       " 'explanation': 'The boy cannot be running from cops and holding onto a gun at the same time.',\n",
       " 'generation_label': 'contradiction',\n",
       " 'fluency': True,\n",
       " '_id': 'main_issue_3',\n",
       " 'explanation_only': 'contradiction',\n",
       " 'explanation_with_premise': 'neutral',\n",
       " 'consistency': False,\n",
       " 'majority_label': 'n',\n",
       " 'label_counter': {'n': 73, 'c': 27, 'e': 0},\n",
       " 'label_rank': {'n': 'high', 'e': 'mid', 'c': 'low'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline('zero-shot-classification',model=hg_model_hub_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "zero-shot-classification: 100%|██████████| 400/400 [02:37<00:00,  2.54it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "candidate_labels = ['grammatical', 'not grammatical']\n",
    "\n",
    "counter1 = 0\n",
    "counter2 = 0\n",
    "for i in tqdm(range(len(processed_data)), desc='zero-shot-classification'):\n",
    "    out = classifier(processed_data[i]['explanation'], candidate_labels)\n",
    "    label_idx = torch.argmax(torch.tensor(out['scores'])).item()\n",
    "    label = candidate_labels[label_idx]\n",
    "    if label == 'grammatical' and processed_data[i]['fluency'] == True:\n",
    "        counter1 += 1\n",
    "    elif label == 'not grammatical' and processed_data[i]['fluency'] == False:\n",
    "        counter2 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "proper_data = []\n",
    "improper_data = []\n",
    "for d in processed_data:\n",
    "    if d['fluency'] == True and d['consistency'] == False:\n",
    "        if d['explanation_with_premise'] == d['generation_label']:\n",
    "            proper_data.append(d)\n",
    "        else:\n",
    "            improper_data.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probs(model, tokenizer, premise, hypothesis):\n",
    "    tokenized_input_seq_pair = tokenizer.encode_plus(premise, hypothesis,\n",
    "                                                    max_length=1024,\n",
    "                                                    return_token_type_ids=True, truncation=True)\n",
    "\n",
    "    input_ids = torch.Tensor(tokenized_input_seq_pair['input_ids']).long().unsqueeze(0)\n",
    "    # remember bart doesn't have 'token_type_ids', remove the line below if you are using bart.\n",
    "    token_type_ids = torch.Tensor(tokenized_input_seq_pair['token_type_ids']).long().unsqueeze(0)\n",
    "    attention_mask = torch.Tensor(tokenized_input_seq_pair['attention_mask']).long().unsqueeze(0)\n",
    "\n",
    "    outputs = model(input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    token_type_ids=token_type_ids,\n",
    "                    labels=None)\n",
    "    \n",
    "    return torch.softmax(outputs[0], dim=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "proper_data:  93%|█████████▎| 178/191 [02:00<00:13,  1.04s/it]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "shifted = 0\n",
    "changed = 0\n",
    "counter = 0\n",
    "prev_probs = []\n",
    "after_probs = []\n",
    "target_probs = []\n",
    "\n",
    "\n",
    "labels = ['entailment', 'neutral', 'contradiction']\n",
    "for i in tqdm(proper_data, desc='proper_data'):\n",
    "    if not 'ibm' in i['uid']:\n",
    "        probs = get_probs(model, tokenizer, i['premise'], i['hypothesis'])\n",
    "        prev_probs.append(torch.log(probs))\n",
    "        e_probs = get_probs(model, tokenizer, i['premise'] + i['explanation'], i['hypothesis'])\n",
    "        after_probs.append(torch.log(e_probs))\n",
    "\n",
    "        target_prob = [i['label_counter'][x] for x in ['e', 'n', 'c']]\n",
    "        target_probs.append(torch.tensor(target_prob)/100)\n",
    "\n",
    "        prev_label = labels[torch.argmax(probs).item()]\n",
    "        e_label = labels[torch.argmax(e_probs).item()]\n",
    "\n",
    "        if prev_label != i['generation_label']:\n",
    "            counter += 1\n",
    "            if e_label == i['generation_label']:\n",
    "                changed += 1\n",
    "            \n",
    "            label_idx = labels.index(i['generation_label'])\n",
    "\n",
    "            if e_probs.tolist()[label_idx] > probs.tolist()[label_idx]:\n",
    "                shifted += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(changed/counter, shifted/counter, counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3147, grad_fn=<DivBackward0>) tensor(1.3756, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "prev_probs = torch.stack(prev_probs, dim = 0)\n",
    "after_probs = torch.stack(after_probs, dim = 0)\n",
    "target_probs = torch.stack(target_probs, dim = 0)\n",
    "\n",
    "kl_loss = torch.nn.KLDivLoss(reduction=\"batchmean\")\n",
    "\n",
    "print(kl_loss(prev_probs, target_probs), kl_loss(after_probs, target_probs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([187, 3])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.8367e+00, -4.9098e+00, -3.5938e+00, -2.5398e-02, -5.4404e+00,\n",
       "         -6.1269e+00, -5.8367e+00, -5.4111e+00, -3.6748e-01, -3.8139e+00,\n",
       "         -4.3025e+00, -1.2362e-02, -9.3099e-01, -3.7105e-02, -9.3099e-01,\n",
       "         -3.5938e+00, -5.8367e+00, -5.4111e+00, -5.7795e+00, -5.1388e-01,\n",
       "         -7.4089e+00, -7.4441e-02, -5.4404e+00, -6.4468e+00, -3.0649e-01,\n",
       "         -4.3025e+00, -4.3025e+00, -3.5938e+00, -6.4468e+00, -5.4404e+00,\n",
       "         -5.8367e+00, -9.3099e-01, -5.8367e+00, -1.5461e-01, -7.4089e+00,\n",
       "         -2.9910e-01, -7.4441e-02, -4.3025e+00, -1.5461e-01, -3.8457e+00,\n",
       "         -1.5461e-01, -4.4528e+00, -7.4441e-02, -3.8139e+00, -3.8457e+00,\n",
       "         -3.8139e+00, -3.8139e+00, -3.0649e-01, -3.6748e-01, -3.7105e-02,\n",
       "         -5.8367e+00, -3.8457e+00, -4.4528e+00, -1.9898e+00, -6.1269e+00,\n",
       "         -4.4528e+00, -1.5461e-01, -7.4089e+00, -2.5398e-02],\n",
       "        [-4.6556e-03, -2.1488e-02, -3.7028e-02, -3.7292e+00, -1.4292e-02,\n",
       "         -5.3826e-01, -4.6556e-03, -9.9787e-01, -1.2054e+00, -2.3628e-02,\n",
       "         -2.6652e-01, -4.4534e+00, -7.4459e-01, -3.3357e+00, -7.4459e-01,\n",
       "         -3.7028e-02, -4.6556e-03, -9.9787e-01, -1.9448e-01, -2.1167e+00,\n",
       "         -3.4202e+00, -2.6520e+00, -1.4292e-02, -4.9585e-03, -1.3390e+00,\n",
       "         -2.6652e-01, -2.6652e-01, -3.7028e-02, -4.9585e-03, -1.4292e-02,\n",
       "         -4.6556e-03, -7.4459e-01, -4.6556e-03, -1.9985e+00, -3.4202e+00,\n",
       "         -1.3584e+00, -2.6520e+00, -2.6652e-01, -1.9985e+00, -7.4642e-02,\n",
       "         -1.9985e+00, -9.1065e-01, -2.6520e+00, -2.3628e-02, -7.4642e-02,\n",
       "         -2.3628e-02, -2.3628e-02, -1.3390e+00, -1.2054e+00, -3.3357e+00,\n",
       "         -4.6556e-03, -7.4642e-02, -9.1065e-01, -1.5035e-01, -5.3826e-01,\n",
       "         -9.1065e-01, -1.9985e+00, -3.4202e+00, -3.7292e+00],\n",
       "        [-6.3618e+00, -4.2770e+00, -4.7265e+00, -6.8430e+00, -4.6200e+00,\n",
       "         -8.8177e-01, -6.3618e+00, -4.6702e-01, -4.8356e+00, -6.6530e+00,\n",
       "         -1.5122e+00, -7.3422e+00, -2.0333e+00, -7.0886e+00, -2.0333e+00,\n",
       "         -4.7265e+00, -6.3618e+00, -4.6702e-01, -1.7507e+00, -1.2680e+00,\n",
       "         -3.3879e-02, -6.7005e+00, -4.6200e+00, -5.6956e+00, -6.2897e+00,\n",
       "         -1.5122e+00, -1.5122e+00, -4.7265e+00, -5.6956e+00, -4.6200e+00,\n",
       "         -6.3618e+00, -2.0333e+00, -6.3618e+00, -4.8645e+00, -3.3879e-02,\n",
       "         -6.5314e+00, -6.7005e+00, -1.5122e+00, -4.8645e+00, -2.9847e+00,\n",
       "         -4.8645e+00, -5.3428e-01, -6.7005e+00, -6.6530e+00, -2.9847e+00,\n",
       "         -6.6530e+00, -6.6530e+00, -6.2897e+00, -4.8356e+00, -7.0886e+00,\n",
       "         -6.3618e+00, -2.9847e+00, -5.3428e-01, -5.8507e+00, -8.8177e-01,\n",
       "         -5.3428e-01, -4.8645e+00, -3.3879e-02, -6.8430e+00]],\n",
       "       grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f06c0f01de39453a8fdefedf00fb8e62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8878f24f327a42079a6361307ffce801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/948 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b851ce61090a477192006c3b7a64ed40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8513e24722b48cd89ed4e2a28677477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/202 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59cda8cba682433483ad698c08436c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/1.45G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.1005, -1.4663,  5.8797]], grad_fn=<AddmmBackward0>)\n",
      "Premise: Two women are embracing while holding to go packages.\n",
      "Hypothesis: The men are fighting outside a deli.\n",
      "Entailment: 4.627431553672068e-05\n",
      "Neutral: 0.0006447185878641903\n",
      "Contradiction: 0.9993090629577637\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp_gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
